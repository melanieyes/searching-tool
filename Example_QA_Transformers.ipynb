{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torchtext==0.15.1\n","!pip install torch==2.1.0\n","!pip install transformers==4.27.1\n","!pip install datasets==2.17.0"],"metadata":{"id":"eeSrirQdxmYe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LCKxEJf5M1q-","executionInfo":{"status":"ok","timestamp":1708097073015,"user_tz":-420,"elapsed":3901,"user":{"displayName":"Thắng Dương","userId":"16346474942041582373"}},"outputId":"b1347bf1-630e-40ad-bba3-5f97ee3e3e80"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":1}],"source":["import torch\n","import torch.nn as nn\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset, DataLoader\n","\n","qa_dataset = [\n","    {\n","        'context': 'My name is AIVN and I am from Vietnam.',\n","        'question': 'What is my name?',\n","        'answer': 'AIVN'\n","    },\n","    {\n","        'context': 'I love painting and my favorite artist is Vincent Van Gogh.',\n","        'question': 'What is my favorite activity?',\n","        'answer': 'painting'\n","    },\n","    {\n","        'context': 'I am studying computer science at the University of Tokyo.',\n","        'question': 'What am I studying?',\n","        'answer': 'computer science'\n","    },\n","    {\n","        'context': 'My favorite book is \"To Kill a Mockingbird\" by Harper Lee.',\n","        'question': 'What is my favorite book?',\n","        'answer': '\"To Kill a Mockingbird\"'\n","    },\n","    {\n","        'context': 'I have a pet dog named Max who loves to play fetch.',\n","        'question': 'What is the name of my pet?',\n","        'answer': 'Max'\n","    },\n","    {\n","        'context': 'I was born in Paris, but now I live in New York City.',\n","        'question': 'Where do I live now?',\n","        'answer': 'New York City'\n","    }\n","]\n","\n","data_size = len(qa_dataset)\n","data_size"]},{"cell_type":"code","source":["# Define tokenizer function\n","tokenizer = get_tokenizer('basic_english')\n","\n","# Create a function to yield list of tokens\n","def yield_tokens(data):\n","    for item in data:\n","        yield tokenizer('<cls> ' + item['context'] + ' <sep> ' + item['question'])\n","\n","# Create vocabulary\n","vocab = build_vocab_from_iterator(\n","    yield_tokens(qa_dataset),\n","    specials=['<unk>', '<pad>', '<bos>', '<eos>', '<sep>', '<cls>']\n",")\n","vocab.set_default_index(vocab['<unk>'])\n","vocab.get_stoi()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GwUwOdfSNC1k","executionInfo":{"status":"ok","timestamp":1708097073458,"user_tz":-420,"elapsed":446,"user":{"displayName":"Thắng Dương","userId":"16346474942041582373"}},"outputId":"0703c32e-eae9-4943-fdfc-bf5477474703"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'vincent': 59,\n"," 'to': 25,\n"," ',': 26,\n"," 'pet': 22,\n"," 'who': 62,\n"," 'gogh': 40,\n"," 'the': 24,\n"," 'fetch': 38,\n"," 'play': 53,\n"," 'van': 57,\n"," 'now': 20,\n"," 'was': 60,\n"," 'a': 15,\n"," 'name': 14,\n"," 'am': 13,\n"," 'named': 49,\n"," 'aivn': 28,\n"," 'i': 6,\n"," 'studying': 23,\n"," 'and': 16,\n"," 'where': 61,\n"," '<unk>': 0,\n"," 'favorite': 12,\n"," 'by': 33,\n"," 'artist': 29,\n"," 'live': 19,\n"," '<eos>': 3,\n"," 'harper': 41,\n"," 'dog': 37,\n"," 'loves': 46,\n"," '.': 9,\n"," 'born': 31,\n"," '<pad>': 1,\n"," 'computer': 35,\n"," '<cls>': 5,\n"," 'is': 7,\n"," 'my': 8,\n"," 'book': 17,\n"," 'science': 54,\n"," 'of': 21,\n"," '<bos>': 2,\n"," '<sep>': 4,\n"," 'what': 11,\n"," 'at': 30,\n"," 'but': 32,\n"," 'in': 18,\n"," 'from': 39,\n"," 'tokyo': 55,\n"," 'city': 34,\n"," 'have': 42,\n"," 'kill': 43,\n"," 'lee': 44,\n"," 'love': 45,\n"," '?': 10,\n"," 'do': 36,\n"," 'max': 47,\n"," 'mockingbird': 48,\n"," 'york': 63,\n"," 'new': 50,\n"," 'painting': 51,\n"," 'paris': 52,\n"," 'university': 56,\n"," 'activity': 27,\n"," 'vietnam': 58}"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["MAX_SEQ_LEN = 22\n","PAD_IDX = vocab['<pad>']\n","\n","def pad_and_truncate(input_ids, max_seq_len):\n","    if len(input_ids) > max_seq_len:\n","        input_ids = input_ids[:max_seq_len]\n","    elif len(input_ids) < max_seq_len:\n","        input_ids += [PAD_IDX] * (max_seq_len - len(input_ids))\n","\n","    return input_ids\n","\n","def vectorize(question, context, answer):\n","    input_text = '<cls> ' + question + ' <sep> ' + context\n","    input_ids = [vocab[token] for token in tokenizer(input_text)]\n","    input_ids = pad_and_truncate(input_ids, MAX_SEQ_LEN)\n","\n","    answer_ids = [vocab[token] for token in tokenizer(answer)]\n","    start_positions = input_ids.index(answer_ids[0])\n","    end_positions = start_positions + len(answer_ids) - 1\n","\n","    input_ids = torch.tensor(input_ids, dtype=torch.long)\n","    start_positions = torch.tensor(start_positions, dtype=torch.long)\n","    end_positions = torch.tensor(end_positions, dtype=torch.long)\n","\n","    return input_ids, start_positions, end_positions"],"metadata":{"id":"_ipp2MjGPqCC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class QADataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        question_text = item['question']\n","        context_text = item['context']\n","        answer_text = item['answer']\n","\n","        input_ids, start_positions, end_positions = vectorize(\n","            question_text, context_text, answer_text\n","        )\n","\n","        return input_ids, start_positions, end_positions"],"metadata":{"id":"B6Mz5YBb9QKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decode(input_ids):\n","    return ' '.join([vocab.lookup_token(token) for token in input_ids])"],"metadata":{"id":"ZFEpfviNKnVG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for item in qa_dataset:\n","    question_text = item['question']\n","    context_text = item['context']\n","    answer_text = item['answer']\n","    input_ids, start_positions, end_positions = vectorize(question_text, context_text, answer_text)\n","    print(input_ids)\n","    text = decode(input_ids)\n","    answer_span = input_ids[start_positions:end_positions+1]\n","\n","    print(text)\n","    print(decode(answer_span))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7e4BsZPKvNI","executionInfo":{"status":"ok","timestamp":1708097073458,"user_tz":-420,"elapsed":5,"user":{"displayName":"Thắng Dương","userId":"16346474942041582373"}},"outputId":"77f7eec9-e2b6-4457-ff22-aa2b008a973e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 5, 11,  7,  8, 14, 10,  4,  8, 14,  7, 28, 16,  6, 13, 39, 58,  9,  1,\n","         1,  1,  1,  1])\n","<cls> what is my name ? <sep> my name is aivn and i am from vietnam . <pad> <pad> <pad> <pad> <pad>\n","aivn\n","tensor([ 5, 11,  7,  8, 12, 27, 10,  4,  6, 45, 51, 16,  8, 12, 29,  7, 59, 57,\n","        40,  9,  1,  1])\n","<cls> what is my favorite activity ? <sep> i love painting and my favorite artist is vincent van gogh . <pad> <pad>\n","painting\n","tensor([ 5, 11, 13,  6, 23, 10,  4,  6, 13, 23, 35, 54, 30, 24, 56, 21, 55,  9,\n","         1,  1,  1,  1])\n","<cls> what am i studying ? <sep> i am studying computer science at the university of tokyo . <pad> <pad> <pad> <pad>\n","computer science\n","tensor([ 5, 11,  7,  8, 12, 17, 10,  4,  8, 12, 17,  7, 25, 43, 15, 48, 33, 41,\n","        44,  9,  1,  1])\n","<cls> what is my favorite book ? <sep> my favorite book is to kill a mockingbird by harper lee . <pad> <pad>\n","to kill a mockingbird\n","tensor([ 5, 11,  7, 24, 14, 21,  8, 22, 10,  4,  6, 42, 15, 22, 37, 49, 47, 62,\n","        46, 25, 53, 38])\n","<cls> what is the name of my pet ? <sep> i have a pet dog named max who loves to play fetch\n","max\n","tensor([ 5, 61, 36,  6, 19, 20, 10,  4,  6, 60, 31, 18, 52, 26, 32, 20,  6, 19,\n","        18, 50, 63, 34])\n","<cls> where do i live now ? <sep> i was born in paris , but now i live in new york city\n","new york city\n"]}]},{"cell_type":"code","source":["train_dataset = QADataset(qa_dataset)\n","train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)"],"metadata":{"id":"FQpXzfAWVQT1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class TransformerBlock(nn.Module):\n","    def __init__(self, embed_dim, num_heads, ff_dim):\n","        super().__init__()\n","        self.attn = nn.MultiheadAttention(embed_dim=embed_dim,\n","                                          num_heads=num_heads)\n","        self.ffn = nn.Linear(in_features=embed_dim,\n","                             out_features=ff_dim)\n","        self.layernorm_1 = nn.LayerNorm(normalized_shape=embed_dim)\n","        self.layernorm_2 = nn.LayerNorm(normalized_shape=embed_dim)\n","\n","    def forward(self, query, key, value):\n","        attn_output, _ = self.attn(query, key, value)\n","        out_1 = self.layernorm_1(query + attn_output)\n","        ffn_output = self.ffn(out_1)\n","        x = self.layernorm_2(out_1 + ffn_output)\n","\n","        return x\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","\n","        return x\n","\n","class QAModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, n_heads, ff_dim, max_len):\n","        super(QAModel, self).__init__()\n","        self.input_embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.pos_encoder = PositionalEncoding(embedding_dim, max_len)\n","        self.transformer = TransformerBlock(embedding_dim, n_heads, ff_dim)\n","\n","        self.start_linear = nn.Linear(ff_dim, 1)\n","        self.end_linear = nn.Linear(ff_dim, 1)\n","\n","    def forward(self, text):\n","        input_embedded = self.input_embedding(text)\n","        input_embedded = self.pos_encoder(input_embedded)\n","        transformer_out = self.transformer(input_embedded, input_embedded, input_embedded)\n","        start_logits = self.start_linear(transformer_out).squeeze(-1)\n","        end_logits = self.end_linear(transformer_out).squeeze(-1)\n","\n","        return start_logits, end_logits\n","\n","# Model parameters\n","EMBEDDING_DIM = 128\n","FF_DIM = 128\n","N_HEADS = 1\n","VOCAB_SIZE = len(vocab)\n","\n","model = QAModel(VOCAB_SIZE, EMBEDDING_DIM, N_HEADS, FF_DIM, MAX_SEQ_LEN)\n","\n","input = torch.randint(0, 10, size=(1, 10))\n","print(input.shape)\n","model.eval()\n","with torch.no_grad():\n","    start_logits, end_logits = model(input)\n","\n","print(start_logits.shape)"],"metadata":{"id":"4pEmizXWQRWJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708097073459,"user_tz":-420,"elapsed":4,"user":{"displayName":"Thắng Dương","userId":"16346474942041582373"}},"outputId":"50c5b1c4-2495-4a02-e480-e3e360e679e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 10])\n","torch.Size([1, 10])\n"]}]},{"cell_type":"code","source":["LR = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"_56VK1_3iW2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 10\n","\n","model.train()\n","for _ in range(EPOCHS):\n","    for idx, (input_ids, start_positions, end_positions) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        start_logits, end_logits = model(input_ids)\n","        start_loss = criterion(start_logits, start_positions)\n","        end_loss = criterion(end_logits, end_positions)\n","        total_loss = (start_loss + end_loss) / 2\n","        total_loss.backward()\n","        optimizer.step()\n","        print(total_loss.item())"],"metadata":{"id":"RousJ01Mk8VJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708097076989,"user_tz":-420,"elapsed":825,"user":{"displayName":"Thắng Dương","userId":"16346474942041582373"}},"outputId":"e79c19c5-6dfc-4a8a-efd5-e6038db1330a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.1906681060791016\n","3.0200304985046387\n","3.717452049255371\n","3.034095287322998\n","2.224654197692871\n","3.13753342628479\n","1.8548295497894287\n","2.875330924987793\n","1.7314162254333496\n","1.935828447341919\n","1.2891161441802979\n","1.709120750427246\n","1.2487807273864746\n","0.9418723583221436\n","1.5946886539459229\n","0.8978770971298218\n","0.737031877040863\n","1.4568142890930176\n","1.0518808364868164\n","0.5805083513259888\n","0.6011573672294617\n","0.37238582968711853\n","0.38469740748405457\n","0.30013278126716614\n","0.34407907724380493\n","0.47778111696243286\n","0.06372884660959244\n","0.14127442240715027\n","0.2023245245218277\n","0.1742343306541443\n"]}]},{"cell_type":"code","source":["model.eval()\n","with torch.no_grad():\n","    sample = qa_dataset[4]\n","    context, question, answer = sample.values()\n","    input_ids, start_positions, end_positions = vectorize(question, context, answer)\n","    input_ids = input_ids.unsqueeze(0)\n","    start_logits, end_logits = model(input_ids)\n","\n","    offset = len(tokenizer(question)) + 2\n","    start_position = torch.argmax(start_logits, dim=1).numpy()[0]\n","    end_position = torch.argmax(end_logits, dim=1).numpy()[0]\n","\n","    start_position -= offset\n","    end_position -= offset\n","\n","    start_position = max(start_position, 0)\n","    end_position = min(end_position, len(tokenizer(context)) - 1)\n","\n","    if end_position >= start_position:\n","        # Extract the predicted answer span\n","        context_tokens = tokenizer(context)\n","        predicted_answer_tokens = context_tokens[start_position:end_position + 1]\n","        predicted_answer = ' '.join(predicted_answer_tokens)\n","    else:\n","        predicted_answer = ''\n","\n","    print(f'Context: {context}')\n","    print(f'Question: {question}')\n","    print(f'Start position: {start_position}')\n","    print(f'End position: {end_position}')\n","    print(f'Answer span: {predicted_answer}')"],"metadata":{"id":"-pe0Jm9zixF7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708097133358,"user_tz":-420,"elapsed":3,"user":{"displayName":"Thắng Dương","userId":"16346474942041582373"}},"outputId":"b4499320-59f3-4d5e-9bb9-c538e5602301"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Context: I have a pet dog named Max who loves to play fetch.\n","Question: What is the name of my pet?\n","Start position: 6\n","End position: 6\n","Answer span: max\n"]}]}]}